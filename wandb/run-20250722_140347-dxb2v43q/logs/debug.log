2025-07-22 14:03:47,730 INFO    MainThread:3388 [wandb_setup.py:_flush():81] Current SDK version is 0.20.1
2025-07-22 14:03:47,730 INFO    MainThread:3388 [wandb_setup.py:_flush():81] Configure stats pid to 3388
2025-07-22 14:03:47,730 INFO    MainThread:3388 [wandb_setup.py:_flush():81] Loading settings from C:\Users\etoma\.config\wandb\settings
2025-07-22 14:03:47,730 INFO    MainThread:3388 [wandb_setup.py:_flush():81] Loading settings from C:\Users\etoma\OneDrive\Documents\GitHub\qrm_optimal_execution\wandb\settings
2025-07-22 14:03:47,730 INFO    MainThread:3388 [wandb_setup.py:_flush():81] Loading settings from environment variables
2025-07-22 14:03:47,730 INFO    MainThread:3388 [wandb_init.py:setup_run_log_directory():703] Logging user logs to C:\Users\etoma\OneDrive\Documents\GitHub\qrm_optimal_execution\wandb\run-20250722_140347-dxb2v43q\logs\debug.log
2025-07-22 14:03:47,731 INFO    MainThread:3388 [wandb_init.py:setup_run_log_directory():704] Logging internal logs to C:\Users\etoma\OneDrive\Documents\GitHub\qrm_optimal_execution\wandb\run-20250722_140347-dxb2v43q\logs\debug-internal.log
2025-07-22 14:03:47,731 INFO    MainThread:3388 [wandb_init.py:init():831] calling init triggers
2025-07-22 14:03:47,731 INFO    MainThread:3388 [wandb_init.py:init():836] wandb.init called with sweep_config: {}
config: {'mode': 'train', 'seed': 42, 'episodes': 5000, 'normal_prices': True, 'basic_state': True, 'len_state_lob': 3, 'action_ask_vol': True, 'safety_test': False, 'time_horizon': 10000, 'trader_time_step': 1000, 'initial_inventory': 30, 'actions': [0, 1], 'history_size': 1, 'final_penalty': 1, 'risk_aversion': 0.0, 'alpha_ramp': 15, 'exec_security_margin': 1, 'price_offset': 0.0, 'price_std': 0.3, 'vol_offset': 5, 'vol_std': 4, 'theta': 0.6, 'theta_reinit': 0.85, 'tick': 0.01, 'arrival_price': 100.005, 'epsilon_start': 1.0, 'epsilon_end': 0.0, 'epsilon_decay': 0.995, 'prop_greedy_eps': 0.09, 'prop_deter_strats': 0.0, 'unif_deter_strats': False, 'gamma': 1.0, 'learning_rate': 0.0001, 'alpha': 0.95, 'eps': 0.01, 'batch_size': 64, 'memory_capacity': 300000, 'warmup_steps': 64, 'target_update_freq': 100, 'target_update_freq_2': 100, 'dynamic_lr': False, 'dynamic_batch_size': False, 'logging_every': 10, 'folder_path_intensity_table': 'calibration_data/intensity_table/', 'folder_path_invariant': 'calibration_data/invariant_distribution/', 'total_timesteps': 50000.0, 'trader_times': array([    0,  1000,  2000,  3000,  4000,  5000,  6000,  7000,  8000,
        9000, 10000]), 'action_dim': 2, 'state_dim': 3, 'proba_0': 0.5, 'max_events_intra': 200000, 'max_events': 2200000, 'file_name': 'qrm_paper.npy', 'file_name_bid': 'qrm_paper.npy', 'file_name_ask': 'qrm_paper.npy', '_wandb': {}}
2025-07-22 14:03:47,731 INFO    MainThread:3388 [wandb_init.py:init():872] starting backend
2025-07-22 14:03:47,961 INFO    MainThread:3388 [wandb_init.py:init():875] sending inform_init request
2025-07-22 14:03:47,990 INFO    MainThread:3388 [wandb_init.py:init():883] backend started and connected
2025-07-22 14:03:47,992 INFO    MainThread:3388 [wandb_init.py:init():956] updated telemetry
2025-07-22 14:03:48,061 INFO    MainThread:3388 [wandb_init.py:init():980] communicating run to backend with 90.0 second timeout
2025-07-22 14:03:49,870 INFO    MainThread:3388 [wandb_init.py:init():1032] starting run threads in backend
2025-07-22 14:03:50,029 INFO    MainThread:3388 [wandb_run.py:_console_start():2453] atexit reg
2025-07-22 14:03:50,029 INFO    MainThread:3388 [wandb_run.py:_redirect():2301] redirect: wrap_raw
2025-07-22 14:03:50,030 INFO    MainThread:3388 [wandb_run.py:_redirect():2370] Wrapping output streams.
2025-07-22 14:03:50,030 INFO    MainThread:3388 [wandb_run.py:_redirect():2393] Redirects installed.
2025-07-22 14:03:50,035 INFO    MainThread:3388 [wandb_init.py:init():1078] run started, returning control to user process
2025-07-22 14:04:00,299 INFO    MainThread:3388 [wandb_run.py:_config_callback():1358] config_cb None None {'algo': 'DQN', 'policy_class': "<class 'stable_baselines3.dqn.policies.DQNPolicy'>", 'device': 'cpu', 'verbose': 1, 'policy_kwargs': "{'net_arch': [256, 256]}", 'num_timesteps': 0, '_total_timesteps': 50000.0, '_num_timesteps_at_start': 0, 'action_noise': 'None', 'start_time': 1753185832135865900, 'tensorboard_log': 'None', '_last_obs': '[[ 1.         -0.8        -0.01666667]]', '_last_episode_starts': '[ True]', '_last_original_obs': 'None', '_episode_num': 0, 'use_sde': 'False', 'sde_sample_freq': -1, '_current_progress_remaining': 1.0, '_stats_window_size': 100, 'ep_info_buffer': 'deque([], maxlen=100)', 'ep_success_buffer': 'deque([], maxlen=100)', '_n_updates': 0, '_custom_logger': 'False', 'env': '<stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x0000027F747F9BE0>', '_vec_normalize_env': 'None', 'observation_space': 'Box(-inf, inf, (3,), float32)', 'action_space': 'Discrete(2)', 'n_envs': 1, 'buffer_size': 300000, 'learning_starts': 100, 'tau': 1.0, 'gradient_steps': 1, 'optimize_memory_usage': 'False', 'replay_buffer': '<stable_baselines3.common.buffers.ReplayBuffer object at 0x0000027F747F9A90>', 'replay_buffer_class': "<class 'stable_baselines3.common.buffers.ReplayBuffer'>", 'replay_buffer_kwargs': '{}', '_episode_storage': 'None', 'train_freq': "TrainFreq(frequency=1, unit=<TrainFrequencyUnit.STEP: 'step'>)", 'use_sde_at_warmup': 'False', 'exploration_initial_eps': 1.0, 'exploration_final_eps': 0.0, 'exploration_fraction': 0.09, 'target_update_interval': 100, '_n_calls': 0, 'max_grad_norm': 10, 'exploration_rate': 0.0, 'lr_schedule': '<function get_schedule_fn.<locals>.<lambda> at 0x0000027F74813A60>', 'policy': 'DQNPolicy(\n  (q_net): QNetwork(\n    (features_extractor): FlattenExtractor(\n      (flatten): Flatten(start_dim=1, end_dim=-1)\n    )\n    (q_net): Sequential(\n      (0): Linear(in_features=3, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=2, bias=True)\n    )\n  )\n  (q_net_target): QNetwork(\n    (features_extractor): FlattenExtractor(\n      (flatten): Flatten(start_dim=1, end_dim=-1)\n    )\n    (q_net): Sequential(\n      (0): Linear(in_features=3, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=2, bias=True)\n    )\n  )\n)', 'q_net': 'QNetwork(\n  (features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (q_net): Sequential(\n    (0): Linear(in_features=3, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=2, bias=True)\n  )\n)', 'q_net_target': 'QNetwork(\n  (features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (q_net): Sequential(\n    (0): Linear(in_features=3, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=2, bias=True)\n  )\n)', 'batch_norm_stats': '[]', 'batch_norm_stats_target': '[]', 'exploration_schedule': '<function get_linear_fn.<locals>.func at 0x0000027F78E0D440>', '_logger': '<stable_baselines3.common.logger.Logger object at 0x0000027F7A5A7A10>'}
2025-07-22 14:08:16,392 INFO    MsgRouterThr:3388 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
